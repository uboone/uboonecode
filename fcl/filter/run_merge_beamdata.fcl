#include "services_microboone.fcl"
#include "beamdata_microboone.fcl"
#include "time_memory_tracker_microboone.fcl"

process_name: BeamData

services:
{
  scheduler:            { defaultExceptions: false }    # Make all uncaught exceptions fatal.
  TFileService:         { fileName: "beamdataquality_hist.root" }
  TimeTracker:          @local::microboone_time_tracker
  MemoryTracker:        @local::microboone_memory_tracker
  FileCatalogMetadata:  @local::art_file_catalog_data
  IFDH: {}
}

#source is now a root file
source:
{
  module_type: RootInput
  maxEvents:  10        # Number of events to create
  inputCommands: ["keep *_*_*_*", "drop raw::BeamInfo_beamdata_*_*" ]
  saveMemoryObjectThreshold: 0
}

# Define and configure some modules to do work on each event.
# First modules are defined; they are scheduled later.
# Modules are grouped by type.
physics:
{

 producers:
 {
   beamdata: @local::microboone_beamdata   
 }

 # Merge beam data path.
 merge: [ beamdata ]
 
 #define the output stream, there could be more than one if using filters 
 stream1:  [ out1 ]

 trigger_paths: [ merge ] 

 end_paths:     [ stream1 ]  
}

#block to define where the output goes.  if you defined a filter in the physics
#block and put it in the trigger_paths then you need to put a SelectEvents: {SelectEvents: [XXX]}
#entry in the output stream you want those to go to, where XXX is the label of the filter module(s)
outputs:
{
 out1:
 {
   module_type: RootOutput
   fileName:    "%ifb_%tc_beamdata.root"
   dataTier:    "reconstructed"
   saveMemoryObjectThreshold: 0
   compressionLevel: 1
 }
}

microboone_tfile_metadata:
{
  JSONFileName:          [ "beamdataquality_hist.root.json" ]
  GenerateTFileMetadata: [ true ]
  dataTier:              [ "root-tuple" ]
  fileFormat:            [ "root" ]
}
